{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit Recognizer (MNIST).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kugmax/tensorflow_learn/blob/master/Digit_Recognizer_(MNIST).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DZeGziUd03tJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "db5cd1ea-5595-4ffc-ab17-da75ab26726f"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.contrib as tf_contrib\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.python.framework import ops\n",
        "import time\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VhaffahNjc42",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ops.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C0Ow91tDgCDw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from tensorboardcolab import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8McR_JyfgDy5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tbc=TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xd4EN4_YgvA2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(X_train, X_test):\n",
        "\n",
        "  mean = np.mean(X_train, axis=(0, 1, 2, 3))\n",
        "  std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "\n",
        "  X_train = (X_train - mean) / std\n",
        "  X_test = (X_test - mean) / std\n",
        "\n",
        "  return X_train, X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v38ELWX3a4fs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_mnist() :\n",
        "    (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "    train_data = np.expand_dims(train_data, axis=-1)\n",
        "    test_data = np.expand_dims(test_data, axis=-1)\n",
        "\n",
        "#  TODO:   Why? For it there is batch norm in restnet\n",
        "    train_data, test_data = normalize(train_data, test_data)\n",
        "\n",
        "    train_labels = to_categorical(train_labels, 10)\n",
        "    test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "    seed = 7\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(train_data)\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(train_labels)\n",
        "    \n",
        "    return train_data, train_labels, test_data, test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RB-prRCjgf5H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x, train_y, test_x, test_y = load_mnist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lOrYyN56gkVo",
        "colab_type": "code",
        "outputId": "45101224-8ce1-45a3-dc95-9eb9050e8e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (60000, 10), (10000, 28, 28, 1), (10000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "UU2pZXc8fTkH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_size = 28\n",
        "c_dim = 1\n",
        "label_dim = 10\n",
        "\n",
        "checkpoint_dir = './checkpoint_dir'\n",
        "log_dir = './log'\n",
        "\n",
        "epoches = 100\n",
        "batch_size = 100\n",
        "iteration = len(train_x) // batch_size\n",
        "\n",
        "init_lr = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8eaRSxR91QBL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_y[55]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "60QSglEE1I0M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_x[55]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWHKXGbmhXJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7b6fBcDfhsmN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_img(img, title=\"\"):\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vASzKxa8h4kM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#show_img(train_x[55], train_y[55])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mbi3DqtHd09Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y6n8gjxah7qk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weight_init = tf_contrib.layers.variance_scaling_initializer()\n",
        "weight_regularizer = tf_contrib.layers.l2_regularizer(0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m12r3Nu-UQou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv(x, channels, kernel=4, stride=2, padding='SAME', use_bias=True, scope='conv_0'):\n",
        "  with tf.variable_scope(scope):\n",
        "    x = tf.layers.conv2d(inputs=x, filters=channels,\n",
        "                         kernel_size=kernel, kernel_initializer=weight_init,\n",
        "                         kernel_regularizer=weight_regularizer,\n",
        "                         strides=stride, use_bias=use_bias, padding=padding)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWqnRuyxUu9s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batch_norm(x, is_training=True, scope='batch_norm'):\n",
        "  return tf_contrib.layers.batch_norm(x,\n",
        "                                      decay=0.9, epsilon=1e-05,\n",
        "                                      center=True, scale=True, updates_collections=None,\n",
        "                                      is_training=is_training, scope=scope)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r1KopS2LVGDl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return tf.nn.relu(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FfInXGV7c6wV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def global_avg_pooling(x):\n",
        "    gap = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
        "    return gap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdw2VAbRdBWT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def flatten(x) :\n",
        "    return tf.layers.flatten(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J8vHU6a-c-RL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fully_conneted(x, units, use_bias=True, scope='fully_0'):\n",
        "    with tf.variable_scope(scope):\n",
        "        x = flatten(x)\n",
        "        x = tf.layers.dense(x, units=units, kernel_initializer=weight_init, kernel_regularizer=weight_regularizer, use_bias=use_bias)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Krji7Wp8j5DZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  bn-relu-conv2d-bn-relu-conv2d->+input\n",
        "   \n",
        "def resblock(x_init, channels, is_training=True, downsample=False, use_bias=True, scope='resblock'):  \n",
        "  with tf.variable_scope(scope):\n",
        "      x = x_init\n",
        "    \n",
        "      x = batch_norm(x, is_training, scope='batch_norm_0')\n",
        "      x = relu(x)    \n",
        "      if downsample :\n",
        "        x = conv(x, channels, kernel=3, stride=2, use_bias=use_bias, scope='conv_0')\n",
        "        x_init = conv(x_init, channels, kernel=1, stride=2, use_bias=use_bias, scope='conv_init')\n",
        "      else :\n",
        "        x = conv(x, channels, kernel=3, stride=1, use_bias=use_bias, scope='conv_0')\n",
        "\n",
        "      x = batch_norm(x, is_training, scope='batch_norm_1')\n",
        "      x = relu(x)\n",
        "      x = conv(x, channels, kernel=3, stride=1, use_bias=use_bias, scope='conv_1')\n",
        "\n",
        "      return x + x_init\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "inqyhmTaY-QV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(x, is_training=True, reuse=False):\n",
        "  with tf.variable_scope(\"model\", reuse=reuse):\n",
        "      residual_list = [3, 4, 6, 3]\n",
        "      ch = 32\n",
        "\n",
        "      x = conv(x, channels=ch, kernel=3, stride=1, scope='conv')      \n",
        "      for i in range(1, residual_list[0]):\n",
        "        x = resblock(x, channels=ch, is_training=is_training, scope='resblock0_' + str(i))\n",
        "\n",
        "\n",
        "      x = resblock(x, channels=ch*2, is_training=is_training, downsample=True, scope='resblock1_0')\n",
        "      for i in range(1, residual_list[1]):\n",
        "        x = resblock(x, channels=ch*2, is_training=is_training, scope='resblock1_' + str(i))\n",
        "\n",
        "\n",
        "      x = resblock(x, channels=ch*4, is_training=is_training, downsample=True, scope='resblock2_0')\n",
        "      for i in range(1, residual_list[2]):\n",
        "        x = resblock(x, channels=ch*4, is_training=is_training, scope='resblock2_' + str(i))\n",
        "\n",
        "\n",
        "      x = resblock(x, channels=ch*8, is_training=is_training, downsample=True, scope='resblock3_0')\n",
        "      for i in range(1, residual_list[3]):\n",
        "        x = resblock(x, channels=ch*8, is_training=is_training, scope='resblock3_' + str(i))\n",
        "\n",
        "\n",
        "      x = batch_norm(x, is_training, scope='batch_norm')\n",
        "      x = relu(x)\n",
        "\n",
        "      x = global_avg_pooling(x)\n",
        "      x = fully_conneted(x, units=label_dim, scope='logit')\n",
        "\n",
        "      print(x.shape) #must be 10\n",
        "\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yXiNf_bzkr7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classification_loss(logit, label) :\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logit))\n",
        "    prediction = tf.equal(tf.argmax(logit, -1), tf.argmax(label, -1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
        "\n",
        "    return loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XNB9zxJthuuq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1cac0876-46af-4132-9f4b-00720dbfcf34"
      },
      "cell_type": "code",
      "source": [
        "\"\"\" Graph Input \"\"\"\n",
        "train_inptus = tf.placeholder(tf.float32, [batch_size, img_size, img_size, c_dim], name='train_inputs')\n",
        "train_labels = tf.placeholder(tf.float32, [batch_size, label_dim], name='train_labels')\n",
        "\n",
        "test_inptus = tf.placeholder(tf.float32, [len(test_x), img_size, img_size, c_dim], name='test_inputs')\n",
        "test_labels = tf.placeholder(tf.float32, [len(test_y), label_dim], name='test_labels')\n",
        "\n",
        "lr = tf.placeholder(tf.float32, name='learning_rate')\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "train_logits = model(train_inptus)\n",
        "test_logits = model(test_inptus, is_training=False, reuse=True)\n",
        "\n",
        "train_loss, train_accuracy = classification_loss(logit=train_logits, label=train_labels)\n",
        "test_loss, test_accuracy = classification_loss(logit=test_logits, label=test_labels)\n",
        "\n",
        "\n",
        "\"\"\" Training \"\"\"\n",
        "optim = tf.train.MomentumOptimizer(lr, momentum=0.9).minimize(train_loss)\n",
        "\n",
        "\"\"\"\" Summary \"\"\"\n",
        "summary_train_loss = tf.summary.scalar(\"train_loss\", train_loss)\n",
        "summary_train_accuracy = tf.summary.scalar(\"train_accuracy\", train_accuracy)\n",
        "\n",
        "summary_test_loss = tf.summary.scalar(\"test_loss\", test_loss)\n",
        "summary_test_accuracy = tf.summary.scalar(\"test_accuracy\", test_accuracy)\n",
        "\n",
        "train_summary = tf.summary.merge([summary_train_loss, summary_train_accuracy])\n",
        "test_summary = tf.summary.merge([summary_test_loss, summary_test_accuracy])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AiCs5zK3nxcY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _random_crop(batch, crop_shape, padding=None):\n",
        "    oshape = np.shape(batch[0])\n",
        "\n",
        "    if padding:\n",
        "        oshape = (oshape[0] + 2 * padding, oshape[1] + 2 * padding)\n",
        "    new_batch = []\n",
        "    npad = ((padding, padding), (padding, padding), (0, 0))\n",
        "    for i in range(len(batch)):\n",
        "        new_batch.append(batch[i])\n",
        "        if padding:\n",
        "            new_batch[i] = np.lib.pad(batch[i], pad_width=npad,\n",
        "                                      mode='constant', constant_values=0)\n",
        "        nh = random.randint(0, oshape[0] - crop_shape[0])\n",
        "        nw = random.randint(0, oshape[1] - crop_shape[1])\n",
        "        new_batch[i] = new_batch[i][nh:nh + crop_shape[0],\n",
        "                       nw:nw + crop_shape[1]]\n",
        "    return new_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "91yc0hKemkrU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_augmentation(batch, img_size):\n",
        "  batch = _random_crop(batch, [img_size, img_size], 4)\n",
        "  return batch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OIQNP60NmFeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "#ops.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u73zSahoihbj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_dir = \"{}{}_{}_{}_{}\".format('rest_net', '34', 'MNIST', batch_size, init_lr)\n",
        "# summary writer\n",
        "writer = tf.summary.FileWriter(log_dir + '/' + model_dir, sess.graph)\n",
        "\n",
        "epoch_lr = init_lr\n",
        "start_epoch = 0\n",
        "start_batch_id = 0\n",
        "counter = 1\n",
        "    \n",
        "# loop for epoch\n",
        "start_time = time.time()\n",
        "for epoch in range(start_epoch, epoches):\n",
        "    if epoch == int(epoch * 0.5) or epoch == int(epoch * 0.75) :\n",
        "        epoch_lr = epoch_lr * 0.1                 \n",
        "\n",
        "    # get batch data\n",
        "    for idx in range(start_batch_id, iteration):\n",
        "        batch_x = train_x[idx*batch_size:(idx+1)*batch_size]\n",
        "        batch_y = train_y[idx*batch_size:(idx+1)*batch_size]\n",
        "\n",
        "#TODO:         I have to try with different augmn\n",
        "        batch_x = data_augmentation(batch_x, img_size)        \n",
        "  \n",
        "        \n",
        "  \n",
        "        train_feed_dict = {\n",
        "            train_inptus : batch_x,\n",
        "            train_labels : batch_y,\n",
        "            lr : epoch_lr\n",
        "        }\n",
        "\n",
        "        test_feed_dict = {\n",
        "            test_inptus : test_x,\n",
        "            test_labels : test_y\n",
        "        }\n",
        "                      \n",
        "\n",
        "        #train\n",
        "        _, summary_str, train_loss_tmp, train_accuracy_tmp = sess.run(\n",
        "            [optim, train_summary, train_loss, train_accuracy],\n",
        "            feed_dict=train_feed_dict\n",
        "        )\n",
        "        writer.add_summary(summary_str, counter)\n",
        "\n",
        "        # test\n",
        "        summary_str, test_loss_tmp, test_accuracy_tmp = sess.run(\n",
        "            [test_summary, test_loss, test_accuracy], feed_dict=test_feed_dict)\n",
        "        writer.add_summary(summary_str, counter)\n",
        "\n",
        "        # display training status\n",
        "        counter += 1                        \n",
        "\n",
        "    # After an epoch, start_batch_id is set to zero\n",
        "    # non-zero value is only for the first epoch after loading pre-trained model\n",
        "    start_batch_id = 0    \n",
        "    \n",
        "  if (epoch+1) % 25 == 0:\n",
        "    print(\"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_accuracy: %.2f, test_accuracy: %.2f, learning_rate : %.4f\" \\\n",
        "          % (epoch, idx, iteration, time.time() - start_time, train_accuracy_tmp, test_accuracy_tmp, epoch_lr))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "izm1wDjRmA89",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wrFiM8iLsSNN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}