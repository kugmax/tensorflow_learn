{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Digit Recognizer (MNIST).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kugmax/tensorflow_learn/blob/master/Digit_Recognizer_(MNIST).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DZeGziUd03tJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "btEf7KYb081m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FbWs_mPMNmWO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v38ELWX3a4fs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IGA0YnF7bGmr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_number = 12000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b82vuIex6EeV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds_train = tf.data.Dataset.from_tensor_slices(train)\n",
        "ds_train = ds_train.shuffle(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5VQl8p6mNR5X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds_valid = ds_train.take(val_number)\n",
        "ds_train = ds_train.skip(val_number)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRkcwIbQOYBb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_valid = []\n",
        "y_valid = []\n",
        "for v in ds_valid:\n",
        "  x_valid.append(v[0].numpy())\n",
        "  y_valid.append(v[1].numpy())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eG1TlGW3f-D9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_valid = np.asarray(x_valid, float)\n",
        "y_valid = np.asarray(y_valid, float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aUJagxi0gCat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36069649-146f-407e-b9a4-8e45686e40cd"
      },
      "cell_type": "code",
      "source": [
        "x_valid.shape, y_valid.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12000, 28, 28), (12000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "dMZ3Zak8RbMA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "for v in ds_train:\n",
        "  x_train.append(v[0].numpy())\n",
        "  y_train.append(v[1].numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zCUtTTnvf7dG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.asarray(x_train, float)\n",
        "y_train = np.asarray(y_train, float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O3Lb92ea-V8K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " #?np.asarray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJwm1MRNgHvk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "159f271a-84b0-421d-c628-50a6e7453ea2"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 28, 28), (48000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "8eaRSxR91QBL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f36a1d05-6127-4c63-97d6-284ca523bacc"
      },
      "cell_type": "code",
      "source": [
        "y_train[55]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "60QSglEE1I0M",
        "colab_type": "code",
        "outputId": "c691739b-98e4-4790-ecc8-370a6b0a1362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        }
      },
      "cell_type": "code",
      "source": [
        "x_train[55]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0., 182., 254., 254., 254., 254., 254., 214., 125.,\n",
              "        125., 125.,  35.,  23., 125., 125., 137., 254., 254., 117.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0., 248., 253., 253., 253., 253., 253., 253., 253.,\n",
              "        253., 253., 249., 249., 253., 253., 253., 253., 253., 183.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,  73., 142., 142., 142., 142., 179., 253., 253.,\n",
              "        253., 253., 253., 253., 253., 253., 253., 253., 247.,  66.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   7.,  19.,  19.,\n",
              "         19.,  19.,  19.,  19.,  19., 103., 253., 253., 186.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0., 163., 253., 253., 110.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0., 163., 253., 246.,  71.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,  14., 193., 253., 234.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,  80., 253., 253., 234.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0., 169., 253., 253., 234.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,  36., 234., 253., 253., 132.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,  36., 234., 253., 253., 104.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0., 169., 253., 253., 104.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0., 169., 253., 253., 104.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,  31., 226., 253., 253., 104.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,  46., 253., 253., 253., 187.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,  46., 253., 253., 253., 234.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,  19., 204., 253., 253., 245.,  66.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0., 169., 253., 253., 242.,  48.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0., 166., 253., 253., 234.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,  20., 207., 253., 234.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "zWHKXGbmhXJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7b6fBcDfhsmN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_img(img, title=\"\"):\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vASzKxa8h4kM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "6677b098-230b-47fa-b84b-68828ff9240c"
      },
      "cell_type": "code",
      "source": [
        "show_img(x_train[55], y_train[55])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFZCAYAAAARqQ0OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLAHAgLAEAIP/B27ISNjvNVu/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff3b230cac8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "aa_L2k175fjl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def duplicate_channels(data):  \n",
        "  print(data.shape)\n",
        "\n",
        "  arr = data.reshape(data.shape[0], 784)\n",
        "  print(arr.shape)\n",
        "  \n",
        "  return arr\n",
        "\n",
        "#   arr = np.repeat(arr, 3, axis=1)\n",
        "#   print(arr.shape)\n",
        "\n",
        "#   to_recognize = arr.reshape(data.shape[0], 28, 28, 3)\n",
        "#   print(to_recognize.shape)\n",
        "  \n",
        "#   return to_recognize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "th5xg-Br5klX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cdfb3d44-9d51-413f-ab87-bfb1f2ae7f2d"
      },
      "cell_type": "code",
      "source": [
        "x_train = duplicate_channels(x_train)\n",
        "x_valid = duplicate_channels(x_valid)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 28, 28)\n",
            "(48000, 784)\n",
            "(12000, 28, 28)\n",
            "(12000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y6n8gjxah7qk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# class ResnetIdentityBlock(tf.keras.Model):\n",
        "#   def __init__(self, kernel_size, filters):\n",
        "#     super(ResnetIdentityBlock, self).__init__(name='')     \n",
        "#     filters1, filters2, filters3 = filters\n",
        "    \n",
        "#     self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
        "#     self.bn2a = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "#     self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
        "#     self.bn2b = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "#     self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
        "#     self.bn2c = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "#   def call(self, input_tensor, training=False):\n",
        "#     x = self.conv2a(input_tensor)\n",
        "#     x = self.bn2a(x, training=training)\n",
        "#     x = tf.nn.relu(x)\n",
        "    \n",
        "#     x = self.conv2b(x)\n",
        "#     x = self.bn2b(x, training=training)\n",
        "#     x = tf.nn.relu(x)\n",
        "    \n",
        "#     x = self.conv2c(x)\n",
        "#     x = self.bn2c(x, training=training)\n",
        "    \n",
        "#     x += input_tensor\n",
        "#     return tf.nn.relu(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Krji7Wp8j5DZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# class ResnetIdentityModel(tf.keras.Model):\n",
        "#   def __init__(self, layers, c):\n",
        "#     super(ResnetIdentityModel, self).__init__(name='ResnetIdentityModel')\n",
        "    \n",
        "#     self.blocks = tf.keras.Sequential(\n",
        "#         #[ ResnetIdentityBlock( [10, 10, 10], 5) for layer in layers ]\n",
        "#         [ ResnetIdentityBlock( 5, [10, 10, 10] ) for x in range(7) ]\n",
        "#     )\n",
        "    \n",
        "#     self.out = tf.keras.layers.Dense(c)\n",
        "          \n",
        "#   def call(self, input_tensor, training=False):\n",
        "#     print(input_tensor.shape)\n",
        "    \n",
        "#     x = self.blocks(input_tensor)    \n",
        "#     print(x.shape)\n",
        "    \n",
        "#     x = tf.keras.layers.GlobalMaxPool2D(x)\n",
        "#     print(x.shape)\n",
        "    \n",
        "#     x = x.view(x.size(0), -1)            \n",
        "#     print(x.shape)\n",
        "        \n",
        "#     x = self.out(x)\n",
        "#     print(x.shape)\n",
        "    \n",
        "#     return tf.math.log_softmax(x, dim=-1)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KViL_BU1mwO_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# class ResnetLayer(tf.keras.layers.BatchNormalization):  \n",
        "#   def call(self, x): return x + super().call(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wKc6Rra4kRXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# class Resnet(tf.keras.Model):\n",
        "#     def __init__(self, layers, c):\n",
        "#         super().__init__()                \n",
        "                        \n",
        "#         layers_num = range(len(layers) - 1)\n",
        "        \n",
        "#         self.conv1 = tf.keras.layers.Conv2D(filters=10, kernel_size=5, strides=1, padding='same')\n",
        "                \n",
        "#         self.layers1 = tf.keras.Sequential(\n",
        "#             [tf.keras.layers.BatchNormalization(layers[i+1], layers[i + 1], 1) for i in range(layers_num)]            \n",
        "#         )\n",
        "        \n",
        "#         self.layers2 = tf.keras.Sequential(\n",
        "#             [ResnetLayer(layers[i+1], layers[i + 1], 1) for i in range(layers_num)]            \n",
        "#         )\n",
        "        \n",
        "#         self.layers3 = tf.keras.Sequential(\n",
        "#             [ResnetLayer(layers[i+1], layers[i + 1], 1) for i in range(layers_num)]            \n",
        "#         )\n",
        "        \n",
        "#         self.out = tf.keras.layers.Dense(c)\n",
        "        \n",
        "#     def call(self, x, training=False):\n",
        "#       print(x.shape)\n",
        "#       x = self.conv1(x)\n",
        "        \n",
        "#       for l,l2,l3 in zip(self.layers1, self.layers2, self.layers3):\n",
        "#         x = l3(l2(l(x)))\n",
        "                \n",
        "#         #x = F.adaptive_max_pool2d(x, 1) # jsut calculate the target and do just max pool . 1 x 1 x 10 (minibatch by num features)\n",
        "#         #x = tf.keras.layers.GlobalMaxPool2D(data_format='channels_last', x) # needcheck where chennels are                \n",
        "        \n",
        "#         x = tf.keras.layers.GlobalMaxPool2D(x) # needcheck where chennels are                \n",
        "        \n",
        "# #         print(x.shape)\n",
        "        \n",
        "#         # here must be 10\n",
        "#         x = x.view(x.size(0), -1)        \n",
        "#         return tf.math.log_softmax(self.out(x), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oNQdsi_Tbkvl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9lRrBD8DccIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from tensorboardcolab import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LrIoRKiHbmwF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tbc=TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5PPn83w2mju9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, input_shape=(28 * 28,) ),    \n",
        "    tf.keras.layers.ReLU(),    \n",
        "    tf.keras.layers.Dense(10),    \n",
        "    tf.keras.layers.Softmax()\n",
        "])    \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_GWUKsfNiWoT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model = Resnet([10, 20, 40, 80, 160], 10)\n",
        "#model = ResnetIdentityModel(7, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7tZWkaHAjItv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " # here I have to impl CLR\n",
        "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "optimizer = tf.train.AdagradOptimizer(learning_rate=0.001)\n",
        "#optimizer = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, decay=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3gFUZ2stFZDJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#def nll_loss(y_true, y_pred):\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dKbkcNr7iv7Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer, loss='mean_squared_logarithmic_error', metrics=['accuracy'])\n",
        "\n",
        "#nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lo2gZti8pZNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "46556589-da8d-45c2-f62e-16b339e88eb7"
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "#tf.contrib.summary(model)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fRo76hsu_1E9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7a7067b-c6b6-4a5c-b84d-f4a808a86e14"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 784), (48000,), (12000, 784), (12000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "meAI-sklhIz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1357
        },
        "outputId": "7391fe5c-731f-44ba-8e55-a6843085fb5c"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x = x_train, y = y_train, epochs=3, verbose=1, validation_data=(x_valid, y_valid)\n",
        "          #,callbacks=[TensorBoardColabCallback(tbc)]\n",
        "         )"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 26s 17ms/step - loss: 2.5769 - acc: 0.0000e+00 - val_loss: 2.5633 - val_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1495/1500 [============================>.] - ETA: 0s - loss: 2.5775 - acc: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-54df44c40ae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(x = x_train, y = y_train, epochs=10, verbose=1, validation_data=(x_valid, y_valid)\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0;31m#,callbacks=[TensorBoardColabCallback(tbc)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1612\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1615\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m       return training_distributed.fit_loop(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, class_weight, val_inputs, val_targets, val_sample_weights, batch_size, epochs, verbose, callbacks, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    703\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m           \u001b[0mdo_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m           batch_size=batch_size)\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36miterator_fit_loop\u001b[0;34m(model, inputs, class_weight, steps_per_epoch, epoch_logs, val_inputs, val_targets, val_sample_weights, epochs, verbose, callbacks, validation_steps, do_validation, batch_size)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# Train model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     outs, loss, loss_metrics, masks = _process_single_batch(\n\u001b[0;32m--> 251\u001b[0;31m         model, x, y, sample_weights=sample_weights, training=True)\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, sample_weights, training)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         model.optimizer.apply_gradients(zip(grads,\n\u001b[0;32m--> 523\u001b[0;31m                                             model._collected_trainable_weights))\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    608\u001b[0m           \u001b[0mscope_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"update_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscope_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m           \u001b[0mupdate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mapply_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mupdate_op\u001b[0;34m(self, optimizer, g)\u001b[0m\n\u001b[1;32m    165\u001b[0m       return optimizer._resource_apply_sparse_duplicate_indices(\n\u001b[1;32m    166\u001b[0m           g.values, self._v, g.indices)\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/adagrad.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         use_locking=self._use_locking)\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_apply_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adagrad\u001b[0;34m(var, accum, lr, grad, use_locking, update_slots, name)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;34m\"ResourceApplyAdagrad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0maccum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_locking\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"update_slots\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         update_slots)\n\u001b[0m\u001b[1;32m   1073\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "b2o3dgsReEux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cc69c77c-895b-4402-9e98-ebcf92f5a862"
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "pred = x_valid[i][None, :]\n",
        "print(y_valid[i])\n",
        "\n",
        "#model.predict(pred)\n",
        "\n",
        "model.predict_classes(pred)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "CQh3uCZYi3QH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "950dd1c4-47ec-4cb0-e827-ec596e5055e2"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "SafxBpm_Ih-E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}